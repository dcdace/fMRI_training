{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management\n",
    "\n",
    "## Create a project folder\n",
    "\n",
    "Here is a recommended folder structure for your fMRI project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# ======================================================================\n",
    "# Recommended study directory structure\n",
    "# ======================================================================\n",
    "\n",
    "# project_name                     \n",
    "#    └── code\n",
    "#        └── analysis             # analysis code \n",
    "#        └── preprocessing        # this is where heudiconv, fmriprep, mriqc scripts go\n",
    "#        └── task                 # experimental task code can go here\n",
    "#    └── data                     # this is where BIDS data and its derivatives will be saved\n",
    "#    └── doc                      # manuscript, notebooks \n",
    "#    └── results                  # analysis results\n",
    "#    └── work                     # where intermediate results should be stored\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create it manually or use a simple `command line` command: \n",
    "```bash\n",
    "mkdir -p My_fMRI_study/{code/{analysis,preprocessing,task},data,doc,results,work}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initiate your analysis version control, you'd type the following in the terminal:\n",
    "```bash\n",
    "cd My_fMRI_study\n",
    "git init\n",
    "```\n",
    "\n",
    "You don't need to track everything in your project. Mainly, you'd like to track your analysis scripts, and perhaps your documents. Basically, everything that is **'text based'**. To exclude certain directories from being tracked, you can create a `.gitignore` file and specify there what to exclude from tracking. \n",
    "\n",
    "For example a `.gitignore` file with content showh below, will exclude `data`, `results`, and `work` directories from version control tracking. \n",
    "\n",
    "```bash\n",
    "data\n",
    "results\n",
    "work\n",
    "```\n",
    "\n",
    "For basic `git` commands, see, for example, this [Git Cheat Sheet](https://about.gitlab.com/images/press/git-cheat-sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "## Retrieving the DICOM files\n",
    "\n",
    "`DICOM` files are the raw imaging files that come from the MRI scanner. Usually they are stored on some MRI data server. At the CBU, each imaging project has a unique code. Knowing my project's code, I can locate the raw `DICOM` files on our server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m/mridata/cbu/CBU090817_MR09029/20090803_083228\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090924_MR09029/20090824_095047\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090928_MR09029/20090824_164906\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090931_MR09029/20090825_095125\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090935_MR09029/20090825_164313\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090938_MR09029/20090826_094337\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090942_MR09029/20090826_164150\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090945_MR09029/20090827_093537\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090951_MR09029/20090828_093853\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090954_MR09029/20090828_163356\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090956_MR09029/20090901_095651\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090957_MR09029/20090901_115356\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090958_MR09029/20090901_133852\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090960_MR09029/20090901_165638\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090962_MR09029/20090902_100102\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090964_MR09029/20090902_135553\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090966_MR09029/20090902_171511\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090967_MR09029/20090904_095737\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090968_MR09029/20090904_135928\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU090970_MR09029/20090904_172442\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU091410_MR09029/20091210_131217\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU091425_MR09029/20091214_113536\u001b[0m/\n",
      "\u001b[01;34m/mridata/cbu/CBU091426_MR09029/20091214_121314\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -d /mridata/cbu/*_MR09029/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Imaging Data Structure (BIDS)\n",
    "\n",
    "***!For a more detailed tutorial see: [https://imaging.mrc-cbu.cam.ac.uk/imaging/dicom-bids](https://imaging.mrc-cbu.cam.ac.uk/imaging/dicom-bids).***\n",
    "\n",
    "To proceed with analysis, we need to convert the `DICOMs` to `NIfTI` format and then organise all these files in a 'nice' way.\n",
    "\n",
    "[Brain Imaging Data Structure (**BIDS**)](https://bids-specification.readthedocs.io/en/stable/) is a a standard for organizing and describing neuroimaging (and behavioural) datasets. See [BIDS paper](https://doi.org/10.1038/sdata.2016.44) and http://bids.neuroimaging.io website for more information.\n",
    "\n",
    "How to get your DICOMs into NIfTI and into BIDS?\n",
    "\n",
    "Several tools exist (see a full list [here](https://bids.neuroimaging.io/benefits#converters)). I will here demonstrate a `Python`-based converter [HeuDiConv](https://heudiconv.readthedocs.io/en/latest/index.html). \n",
    "\n",
    "`heudiconv` is a flexible `DICOM` converter for organizing brain imaging data into structured directory layouts.\n",
    "* It allows flexible directory layouts and naming schemes through customizable heuristics implementations\n",
    "* It only converts the necessary DICOMs, not everything in a directory\n",
    "* You can keep links to DICOM files in the participant layout\n",
    "* Using `dcm2niix` under the hood, it’s fast\n",
    "* It provides assistance in converting to `BIDS`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeuDiConv\n",
    "\n",
    "To use HeuDiConv, either install heudiconv and dcm2niix packages locally: \n",
    "```\n",
    "pip install heudiconv==0.13.1\n",
    "conda install -c conda-forge dcm2niix\n",
    "```\n",
    "\n",
    "or use Docker (or Apptainer/Singularity) container image\n",
    "```\n",
    "docker pull nipy/heudiconv\n",
    "```\n",
    "\n",
    "`heidiconv` involves 3 main steps:\n",
    "1. Discovering what DICOM series (scans) there are in your data\n",
    "2. Creating a heuristic file specifying how to translate the DICOMs into BIDS\n",
    "3. Converting the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Discovering your scans\n",
    "\n",
    "First, you need to know what scans there are and how to uniquely identify them by their metadata. You could look in each scan's DICOM file metadata manually yourself, but that's not very convenient. Instead, you can 'ask' HeuDiConv to do the scan discovery for you. If you run HeuDiConv without NIfTI conversion and heuristic, it will generate a DICOM info table with all scans and their metadata. Like this: \n",
    "\n",
    "<img align=\"left\" padding = \"16px;\" src=\"https://imaging.mrc-cbu.cam.ac.uk/imaging/dicom-bids?action=AttachFile&do=get&target=dicom_info.png\">\n",
    "<br clear=\"left\"/>\n",
    "\n",
    "The column names are metadata fields and rows contain their corresponding values.\n",
    "\n",
    "**Example script:**\n",
    "To get such a table, you'd write a simple bash script, like this: [code/step01_dicom_discover.sh](https://github.com/dcdace/fMRI_training/blob/main/code/step01_dicom_discover.sh) script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define your paths\n",
    "# ------------------------------------------------------------\n",
    "# Your project's root directory\n",
    "PROJECT_PATH='/imaging/correia/da05/workshops/2024-CBU'\n",
    "# Path to the raw DICOM files\n",
    "DICOM_PATH='/mridata/cbu/CBU090942_MR09029'\n",
    "# Location of the output data (it will be created if it doesn't exist)\n",
    "OUTPUT_PATH=\"${PROJECT_PATH}/work/dicom_discovery/\"\n",
    "# Subject ID\n",
    "SUBJECT_ID='01'\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run the heudiconv\n",
    "# ------------------------------------------------------------\n",
    "conda activate fmri\n",
    "\n",
    "heudiconv \\\n",
    "    --files \"${DICOM_PATH}\"/*/*/*.dcm \\\n",
    "    --outdir \"${OUTPUT_PATH}\" \\\n",
    "    --heuristic convertall \\\n",
    "    --subjects \"${SUBJECT_ID}\" \\\n",
    "    --converter none \\\n",
    "    --bids \\\n",
    "    --overwrite\n",
    "\n",
    "conda deactivate\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# HeudiConv parameters:\n",
    "# --files: Files or directories containing files to process\n",
    "# --outdir: Output directory\n",
    "# --heuristic: Name of a known heuristic or path to the Python script containing heuristic\n",
    "# --subjects: Subject ID\n",
    "# --converter : dicom to nii converter (dcm2niix or none)\n",
    "# --bids: Flag for output into BIDS structure\n",
    "# --overwrite: Flag to overwrite existing files\n",
    "# \n",
    "# For a full list of parameters, see: https://heudiconv.readthedocs.io/en/latest/usage.html \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the script, the table that we are interested in will be located at `OUTPUT_PATH/.heudiconv/[subject ID]/info/dicominfo.tsv``. The .heudiconv directory is a hidden directory and you might not be able to see it in your file system. If so, either enable to view hidden files, or copy the dicominfo.tsv to some other location. For example, your home Desktop:\n",
    "\n",
    "```bash\n",
    "cp /imaging/correia/da05/wiki/BIDS_conversion/MRI/work/dicom_discovery/.heudiconv/01/info/dicominfo.tsv ~/Desktop\n",
    "```\n",
    "Now, you can open the file, for example, in MS Excel and keep it open for the next step - creating a heuristic file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Creating a heuristic file\n",
    "\n",
    "The `heuristic` file is used to convert and organize the DICOM data into BIDS standard. You will need to define heuristic keys. Keys define type of scan. \n",
    "\n",
    "The key definitions must strictly follow BIDS standart! https://bids-specification.readthedocs.io/en/stable/02-common-principles.html\n",
    "\n",
    "In our example dataset, we have four types of scans: anatomical image, fieldmaps (magnitude and phase), and functional runs. We will need to define the keys for them all. Like this:\n",
    "\n",
    "```python\n",
    "    anat = create_key(\n",
    "        'sub-{subject}/anat/sub-{subject}_T1w'\n",
    "        )\n",
    "    fmap_mag = create_key(\n",
    "        'sub-{subject}/fmap/sub-{subject}_acq-func_magnitude'\n",
    "        )\n",
    "    fmap_phase = create_key(\n",
    "        'sub-{subject}/fmap/sub-{subject}_acq-func_phasediff'\n",
    "        )\n",
    "    func_task = create_key(\n",
    "        'sub-{subject}/func/sub-{subject}_task-facerecognition_run-{item:02d}_bold'\n",
    "        )\n",
    "```\n",
    "\n",
    "Next, we will need to specify unique criteria that only the particular scan will meet. This information we get from the `dicominfo.tsv` file that we 'discovered' in the previous step. For example, to uniquely identify the anatomical scan, we can specify that the `protocol_name` contains `MPRAGE`. We don't have any other scans with MPRAGE in protocol name, therefore for the anatomical scan, we don't need to specify any additional cireteria. Similarly, we would specify unique identifiers for the other three scans. \n",
    "\n",
    "Then we integrate the keys and specifications into a heuristic Python file.\n",
    "\n",
    "**Example heuristic file**: [code/bids_heuristic.py](https://github.com/dcdace/fMRI_training/blob/main/code/bids_heuristic.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def create_key(template, outtype=('nii.gz',), annotation_classes=None):\n",
    "    if template is None or not template:\n",
    "        raise ValueError('Template must be a valid format string')\n",
    "    return template, outtype, annotation_classes\n",
    "\n",
    "def infotodict(seqinfo):\n",
    "    \n",
    "    # Define the keys (file names)\n",
    "    anat = create_key(\n",
    "        'sub-{subject}/anat/sub-{subject}_T1w'\n",
    "        )\n",
    "    fmap_mag = create_key(\n",
    "        'sub-{subject}/fmap/sub-{subject}_acq-func_magnitude'\n",
    "        )\n",
    "    fmap_phase = create_key(\n",
    "        'sub-{subject}/fmap/sub-{subject}_acq-func_phasediff'\n",
    "        )\n",
    "    func_task = create_key(\n",
    "        'sub-{subject}/func/sub-{subject}_task-facerecognition_run-{item:02d}_bold'\n",
    "        )\n",
    "    \n",
    "    # Create the dictionary that will be returned by this function.\n",
    "    info = {\n",
    "        anat: [], \n",
    "        fmap_mag: [], \n",
    "        fmap_phase: [],  \n",
    "        func_task: []\n",
    "        }\n",
    "\n",
    "    # Loop through all the DICOM series and assign them to the appropriate conversion key.\n",
    "    for s in seqinfo:\n",
    "        # Uniquelly identify each series\n",
    "        \n",
    "        # Structural\n",
    "        if \"MPRAGE\" in s.protocol_name:\n",
    "            info[anat].append(s.series_id)\n",
    "            \n",
    "        # Field map Magnitude (the fieldmap with the largest dim3 is the magnitude, the other is the phase)\n",
    "        if (s.dim3 == 66) and ('FieldMapping' in s.protocol_name):\n",
    "            info[fmap_mag].append(s.series_id)\n",
    "            \n",
    "        # Field map PhaseDiff\n",
    "        if (s.dim3 == 33) and ('FieldMapping' in s.protocol_name):\n",
    "            info[fmap_phase].append(s.series_id)\n",
    "\n",
    "        # Functional Bold\n",
    "        if s.dim4 > 100:\n",
    "           info[func_task].append(s.series_id)\n",
    "            \n",
    "    # Return the dictionary\n",
    "    return info\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# Dictionary to specify options to populate the 'IntendedFor' field of the fmap jsons.\n",
    "# --------------------------------------------------------------------------------------\n",
    "POPULATE_INTENDED_FOR_OPTS = {\n",
    "    'matching_parameters': ['ModalityAcquisitionLabel'],\n",
    "    'criterion': 'Closest'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Converting the data\n",
    "\n",
    "##### Conversting a single-subject\n",
    "\n",
    "To convert a single subject, we only need to change 2 things in our previous 'DICOM discovery' script:\n",
    "* the output to be in PROJECT_PATH/data/, \n",
    "* location to the heuristic file that we created in the previous step, and \n",
    "* we specify the DICOM to NIfTI converter (*dcm2niix*), so that the files are actually converted. \n",
    "\n",
    "```bash\n",
    "# ------------------------------------------------------------\n",
    "# Define your paths\n",
    "# ------------------------------------------------------------\n",
    "# Your project's root directory\n",
    "PROJECT_PATH='/imaging/correia/da05/workshops/2024-CBU'\n",
    "# Path to the raw DICOM files\n",
    "DICOM_PATH='/mridata/cbu/CBU090942_MR09029'\n",
    "# Location of the output data (it will be created if it doesn't exist)\n",
    "OUTPUT_PATH=\"${PROJECT_PATH}/data/\"\n",
    "# Subject ID\n",
    "SUBJECT_ID='01'\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run the heudiconv\n",
    "# ------------------------------------------------------------\n",
    "conda activate fmri\n",
    "\n",
    "heudiconv \\\n",
    "    --files \"${DICOM_PATH}\"/*/*/*.dcm \\\n",
    "    --outdir \"${OUTPUT_PATH}\" \\\n",
    "    --heuristic $PROJECT_PATH/code/bids_heuristic.py \\\n",
    "    --subjects \"${SUBJECT_ID}\" \\\n",
    "    --converter dcm2niix \\\n",
    "    --bids \\\n",
    "    --overwrite\n",
    "\n",
    "conda deactivate\n",
    "# ------------------------------------------------------------\n",
    "```\n",
    "To convert other subjects as well, you'd need to change the raw DICOM path and subject ID accordingly. If you have multiple subjects, it's a good idea to process them all together using the scheduling system like SLURM (Simple Linux Utility for Resource Management).\n",
    "\n",
    "##### Converting multiple subjects in parallel using SLURM\n",
    "\n",
    "First, we need a generic script that runs HeuDiConv. It would be very similar to the one above where we converted a single subject. \n",
    "\n",
    "**Example of a generic heudiconv script**: [code/heudiconv_script.sh](https://github.com/dcdace/fMRI_training/blob/main/code/heudiconv_script.sh)\n",
    "\n",
    "Second, you'd need a project-specific script where you define the paths and use the `sbatch` command to execute the generic script for each subject. You can either write your script in bash, or Python if you prefer a more 'user-friendly' syntax. I have written an example script in Python. \n",
    "\n",
    "**Example script to convert multiple subjects' DICOMs to BIDS**: [code/step02_dicom_to_bids.py](https://github.com/dcdace/fMRI_training/blob/main/code/step02_dicom_to_bids.py\n",
    ")\n",
    "The script's main function is to generate a list of subject IDs alongside their corresponding DICOM paths, define the heuristic file's location, specify the output path, and then construct and execute an `sbatch`` command to run the *heudiconv_script.sh*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'To Do' - additional information to check and add\n",
    "\n",
    "Once you have converted the DICOMs to BIDS, there are some things that you need to fill in yourself to make the dataset fully BIDS compliant. HeuDiConv has marked such 'missing' information as 'To Do'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset description\n",
    "\n",
    "`dataset_description.json`\n",
    "\n",
    "A brief description of your dataset. \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"Acknowledgements\": \"TODO: whom you want to acknowledge\",\n",
    "  \"Authors\": [\n",
    "    \"TODO:\",\n",
    "    \"First1 Last1\",\n",
    "    \"First2 Last2\",\n",
    "    \"...\"\n",
    "  ],\n",
    "  \"BIDSVersion\": \"1.8.0\",\n",
    "  \"DatasetDOI\": \"TODO: eventually a DOI for the dataset\",\n",
    "  \"Funding\": [\n",
    "    \"TODO\",\n",
    "    \"GRANT #1\",\n",
    "    \"GRANT #2\"\n",
    "  ],\n",
    "  \"HowToAcknowledge\": \"TODO: describe how to acknowledge -- either cite a corresponding paper, or just in acknowledgement section\",\n",
    "  \"License\": \"TODO: choose a license, e.g. PDDL (http://opendatacommons.org/licenses/pddl/)\",\n",
    "  \"Name\": \"TODO: name of the dataset\",\n",
    "  \"ReferencesAndLinks\": [\n",
    "    \"TODO\",\n",
    "    \"List of papers or websites\"\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participants\n",
    "\n",
    "`participants.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"participant_id\": {\n",
    "    \"Description\": \"Participant identifier\"\n",
    "  },\n",
    "  \"age\": {\n",
    "    \"Description\": \"Age in years (TODO - verify) as in the initial session, might not be correct for other sessions\"\n",
    "  },\n",
    "  \"sex\": {\n",
    "    \"Description\": \"self-rated by participant, M for male/F for female (TODO: verify)\"\n",
    "  },\n",
    "  \"group\": {\n",
    "    \"Description\": \"(TODO: adjust - by default everyone is in control group)\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task information\n",
    "\n",
    "`task-facerecognition_bold.json`\n",
    "\n",
    "Could add full task name and a Cognitive Atlas ID if it exists. \n",
    "```json\n",
    "{\n",
    " ...\n",
    "  \"TaskName\": \"TODO: full task name for facerecognition\",\n",
    " ...\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Events\n",
    "\n",
    "For the functional images, if they are not resting-state images, but participants performed a task, you need to provide the trial type, onset and duration details. HeuDiConv generates the `events.tsv` file for each functional run. The files are just a template that you need to fill with the actual data. You would get this data from tour experimental script outputs (make sure you have programmed your task to easily retrieve the needed trial and timing details). \n",
    "\n",
    "For the example dataset used in this tutorial, I retrieved the event timing information from the [OpenNeuro version of this dataset](https://openneuro.org/datasets/ds000117/versions/1.0.5)\n",
    "\n",
    "**See my script here:** [code/step03_events_to_bids.py](https://github.com/dcdace/fMRI_training/blob/main/code/step03_events_to_bids.py)).\n",
    "\n",
    "The event files in the OpenNeuro version of this dataset, do not fully comply with the current BIDS specification. According to `BIDS` specification for [Task Events](https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/05-task-events.html), a correct column name is *'trial_type'*, not *'stim_type'*. In my script, after downloading the files, I fixed this naming. In addition, I removed the no-name trial types (the 'rest' period) as we don't want to model rest as a separate event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is how an example events file looked generated by HeuDiConv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>response_time</th>\n",
       "      <th>stim_file</th>\n",
       "      <th>TODO -- fill in rows and add more tab-separated columns if desired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [onset, duration, trial_type, response_time, stim_file, TODO -- fill in rows and add more tab-separated columns if desired]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "events_file = 'misc/sub-01_task-facerecognition_run-01_events_before.tsv'\n",
    "events = pd.read_csv(events_file, sep='\\t')\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how it looks after filling in the required details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>circle_duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>button_pushed</th>\n",
       "      <th>response_time</th>\n",
       "      <th>stim_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.534</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.158</td>\n",
       "      <td>func/f013.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.273</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.586</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.233</td>\n",
       "      <td>func/f013.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.647</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.546</td>\n",
       "      <td>UNFAMILIAR</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.183</td>\n",
       "      <td>func/u014.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.838</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.597</td>\n",
       "      <td>UNFAMILIAR</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>func/u014.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.978</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.415</td>\n",
       "      <td>UNFAMILIAR</td>\n",
       "      <td>13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.068</td>\n",
       "      <td>func/u016.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    onset  duration  circle_duration  trial_type  trigger  button_pushed  \\\n",
       "0   0.000     0.908            0.534      FAMOUS        5            4.0   \n",
       "1   3.273     0.962            0.586      FAMOUS        6            4.0   \n",
       "2   6.647     0.825            0.546  UNFAMILIAR       13            4.0   \n",
       "3   9.838     0.968            0.597  UNFAMILIAR       14            4.0   \n",
       "4  12.978     0.904            0.415  UNFAMILIAR       13            7.0   \n",
       "\n",
       "   response_time      stim_file  \n",
       "0          2.158  func/f013.bmp  \n",
       "1          1.233  func/f013.bmp  \n",
       "2          1.183  func/u014.bmp  \n",
       "3          0.930  func/u014.bmp  \n",
       "4          1.068  func/u016.bmp  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_file = 'misc/sub-01_task-facerecognition_run-01_events_after.tsv'\n",
    "events = pd.read_csv(events_file, sep='\\t')\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### README\n",
    "\n",
    "*\"TODO: Provide description for the dataset -- basic details about the study, possibly pointing to pre-registration (if public or embargoed)\"*\n",
    "\n",
    "See an example for the OpenNeuro version of this dataset https://openneuro.org/datasets/ds000117/versions/1.0.5/file-display/README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate BIDS structure\n",
    "\n",
    "Once we have our BIDS dataset, we can use an [online BIDS validator](https://bids-standard.github.io/bids-validator/) to check if our dataset confirms with BIDS standard and what additional information we might need to include in your dataset's metadata. \n",
    "\n",
    "For this example dataset, we get some warnings about events custom columns that have no description. We can include *events.json* file that contains this information. For guidance see the BIDS specification https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/05-task-events.html\n",
    "\n",
    "Suspiciously long event: `sub-10_task-facerecognition_run-09_events.tsv`. We can add this information in the README file: *Owing to scanner error, Subject 10 only has 170 volumes in last run (Run 9) (hence the BIDS warning of some onsets in events.tsv file being later than the data)* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional help on BIDS\n",
    "\n",
    "[CBU's DICOM to BIDS tutorial](https://imaging.mrc-cbu.cam.ac.uk/imaging/dicom-bids)\n",
    "\n",
    "[Neurostars forum, BIDS tag](https://neurostars.org/tags/bids)\n",
    "\n",
    "[Neurohackademy: Kirstie Whitaker - Brain Imaging Data Structure](https://youtu.be/XzfjxbTYQRM?si=5onGWzx8dZ_J1B98&t=1255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/XzfjxbTYQRM?start=1255\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f55bef25d80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('XzfjxbTYQRM', start=1255, width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caution! - Dummy scans\n",
    "\n",
    "When we start acquiring fMRI data, scanner needs some time to reach a steady state. Therefore a common practice is to dicard the first couple of volumes - **the dummy scans** - from the functional acquisitions. Often it is done at the scanner level and we never see these scans. But sometimes we need to discard them ourselves. \n",
    "\n",
    "For the example dataset, used in this tutorial, we need to dicard the first two volumes from each functional run (2 dummy scans). \n",
    "You can exclude them either from the DICOM files before converting to BIDS or from the NIfTI files after BIDS conversion. As I took my DICOM files straight from the MRI server with read-only permissions, I excluded the dummy-scans after I converted the files to BIDS. \n",
    "\n",
    "To remove 2 dummy scans from each functional file in the dataset, I used the following generic bash script which uses `FSL` to remove the volumes:\n",
    "\n",
    "**Example generic script** for removing dummy scans from a 4D NIfTI file: [code/dummies_script.sh](https://github.com/dcdace/fMRI_training/blob/main/code/dummies_script.sh)\n",
    "\n",
    "The script in brief:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "file=$1\n",
    "n_dummies=2\n",
    "\n",
    "echo \"Loading FSL\"\n",
    "module load fsl/6.0.1\n",
    "\n",
    "temp_file=\"${file%.nii.gz}_temp.nii.gz\"\n",
    "echo \"Creating temporary file $temp_file\"\n",
    "\n",
    "echo \"Running fslroi with a temporary output file\"\n",
    "fslroi \"$file\" \"$temp_file\" $n_dummies -1\n",
    "\n",
    "echo \"Replacing the original file with the modified file\"\n",
    "mv \"$temp_file\" \"$file\"\n",
    "\n",
    "echo \"Done!\"\n",
    "```\n",
    "\n",
    "To remove the dummy scans from all functional files in the dataset in parallel, I used this script. The script finds all functional files and runs the 'dummies_script.sh' for each file:\n",
    "\n",
    "**Example script to remove dummy scans from all files in parallel**: [code/step04_remove_dummy_scans.sh](https://github.com/dcdace/fMRI_training/blob/main/code/step04_remove_dummy_scans.sh)\n",
    "\n",
    "The script in brief:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "for run in ${BIDS_DIR}/sub-*/func/*.nii.gz; do\n",
    "    sbatch \\\n",
    "        --job-name=dummies \\\n",
    "        \"$SCRIPT_PATH\" \"$run\"\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PyBIDS\n",
    "\n",
    "`PyBids` is a Python module to interface with datasets conforming BIDS. See the [documentation](https://bids-standard.github.io/pybids/) and [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7409983/) for more info. \n",
    "\n",
    "```\n",
    "pip install pybids\n",
    "```\n",
    "\n",
    "**Let's explore some of the functionality of pybids.layout.** The material is adapted from https://github.com/bids-standard/pybids/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIDS Layout: ...ops/2024-CBU/notebooks/../data | Subjects: 16 | Sessions: 0 | Runs: 144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from bids.layout import BIDSLayout\n",
    "\n",
    "ds_path = '../data'\n",
    "\n",
    "# Initialize the layout\n",
    "layout = BIDSLayout(ds_path)\n",
    "\n",
    "# Print some basic information about the layout\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the BIDSLayout\n",
    "The main method for querying `BIDSLayout` is `.get()`.\n",
    "\n",
    "If we call `.get()` with no additional arguments, we get back a list of all the BIDS files in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 583 files in the layout.\n",
      "\n",
      "The first 5 files are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<BIDSFile filename='/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/CHANGES'>,\n",
       " <BIDSJSONFile filename='/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/dataset_description.json'>,\n",
       " <BIDSJSONFile filename='/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/participants.json'>,\n",
       " <BIDSDataFile filename='/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/participants.tsv'>,\n",
       " <BIDSFile filename='/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/README'>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = layout.get()\n",
    "print(\"There are {} files in the layout.\".format(len(all_files)))\n",
    "print(\"\\nThe first 5 files are:\")\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object is a **Python list**. Each element in the list is a `BIDSFile` object. \n",
    "\n",
    "We can also get just filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/CHANGES',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/dataset_description.json',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/participants.json',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/participants.tsv',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/README']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get(return_type='filename')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get such information as\n",
    "* all `subject` IDs\n",
    "* all `task` names\n",
    "* dataset `description`\n",
    "* the BOLD repetition time TR\n",
    "* how many `runs` there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facerecognition']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acknowledgements': 'TODO: whom you want to acknowledge',\n",
       " 'Authors': ['TODO:', 'First1 Last1', 'First2 Last2', '...'],\n",
       " 'BIDSVersion': '1.8.0',\n",
       " 'DatasetDOI': 'TODO: eventually a DOI for the dataset',\n",
       " 'Funding': ['TODO', 'GRANT #1', 'GRANT #2'],\n",
       " 'HowToAcknowledge': 'TODO: describe how to acknowledge -- either cite a corresponding paper, or just in acknowledgement section',\n",
       " 'License': 'TODO: choose a license, e.g. PDDL (http://opendatacommons.org/licenses/pddl/)',\n",
       " 'Name': 'TODO: name of the dataset',\n",
       " 'ReferencesAndLinks': ['TODO', 'List of papers or websites']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_dataset_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_tr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding runs, it might be that there are varied number of runs accross participants. So, let's get runs for each participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n",
      "[01, 02, 03, 04, 05, 06, 07, 08, 09]\n"
     ]
    }
   ],
   "source": [
    "for sID in layout.get_subjects(): \n",
    "    print(layout.get_runs(subject = sID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering files by entities\n",
    "We can pass any BIDS-defined entities (keywords) to `.get()` method. For example, here's how we would retrieve all BOLD runs with `.nii.gz` extensions for subject `04`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-01_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-02_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-03_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-04_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-05_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-06_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-07_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-08_bold.nii.gz',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04/func/sub-04_task-facerecognition_run-09_bold.nii.gz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve filenames of all BOLD runs for subject\n",
    "layout.get(subject='04', extension='nii.gz', suffix='bold', return_type='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the entities are found in the names of BIDS files. For example `sub-01_task-facerecognition_run-01_bold.nii.gz` has entities: **subject**, **task**, **run**, **suffix**, **extension**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the list of all availabe entities by `layout.get_entities()`.\n",
    "\n",
    "Here are a few of the most common entities:\n",
    "\n",
    "* `suffix`: The part of a BIDS filename just before the extension (e.g., 'bold', 'events', 'T1w', etc.).\n",
    "* `subject`: The subject label\n",
    "* `session`: The session label\n",
    "* `run`: The run index\n",
    "* `task`: The task name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by metadata\n",
    "Sometimes we want to search for files based not just on their names, but also based on metadata defined in JSON files. We can pass any key that occurs in any JSON file in our project as an argument to `.get()`. We can combine these with any number of core BIDS entities (like `subject`, `run`, etc.).\n",
    "\n",
    "For example, we want to retrieve `SpacingBetweenSlices` (measured from center-to-center of each slice, in mm) for all our subjects. And let's create a nice data frame of this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject spacing\n",
      "     01  [3.75]\n",
      "     02   [3.9]\n",
      "     03   [3.9]\n",
      "     04   [3.9]\n",
      "     05  [3.75]\n",
      "     06  [4.05]\n",
      "     07  [3.75]\n",
      "     08  [3.75]\n",
      "     09  [3.75]\n",
      "     10   [3.9]\n",
      "     11  [3.75]\n",
      "     12  [3.75]\n",
      "     13   [3.9]\n",
      "     14  [3.75]\n",
      "     15   [3.9]\n",
      "     16  [4.05]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = []\n",
    "for subject in layout.get_subjects():\n",
    "    d.append(\n",
    "        {\n",
    "            'subject': subject,\n",
    "            'spacing': layout.get_SpacingBetweenSlices(subject=subject, suffix='bold')\n",
    "        }\n",
    "    )\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having different spacing between the slices is rather unusual. But authors were trying to cover the whole cortex. So, larger brains, had larger spacing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================**\n",
    "\n",
    "**EXCERCISE**\n",
    "\n",
    "We want to know the time of the day when each subject was scanned. The scanning started with T1 images, so we want to retrieve the `AcquisitionTime` of all subjects' `T1w` images. Adapt the script above to acquire this information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other `return_type` values\n",
    "We can also ask `get()` to return unique values (or IDs) of particular entities. For example, we want to know which subjects had a fieldmap acquired. We can request that information by setting `return_type='id'` - to get subject IDs. When using this option, we also need to specify a `target` entity for the ID (in this case, subject). This combination tells the `BIDSLayout` to return the unique values for the specified `target` entity. \n",
    "\n",
    "For example, in the next example, we ask for all of the unique subject IDs that have at least one file with a `phasediff` (fieldmap) suffix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask get() to return the ids of subjects that have phasediff (fieldmap_ files)\n",
    "\n",
    "layout.get(return_type='id', target='subject', suffix='phasediff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our `target` is a BIDS entity that corresponds to a particular directory in the BIDS specification (e.g., `subject` or `session`) we can also use `return_type='dir'` to get all matching subdirectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-01',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-02',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-03',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-04',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-05',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-06',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-07',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-08',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-09',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-10',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-11',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-12',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-13',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-14',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-15',\n",
       " '/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-16']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get(return_type='dir', target='subject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `BIDSFile`\n",
    "When you call `.get()` on a `BIDSLayout`, the default returned values are objects of class `BIDSFile`. A `BIDSFile` is a lightweight container for individual files in a BIDS dataset. It provides easy access to a variety of useful attributes and methods. Let's take a closer look. First, let's pick a random file from our existing `layout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BIDSImageFile filename='/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-01/anat/sub-01_T1w.nii.gz'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick the 7th file in the dataset\n",
    "bf = layout.get()[7]\n",
    "# Print it\n",
    "bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the attributes and methods available to us in a `BIDSFile` (note that some of these are only available for certain subclasses of `BIDSFile`; e.g., you can't call `get_image()` on a `BIDSFile` that doesn't correspond to an image file!):\n",
    "* `.path`: The full path of the associated file\n",
    "* `.filename`: The associated file's filename (without directory)\n",
    "* `.dirname`: The directory containing the file\n",
    "* `.get_entities()`: Returns information about entities associated with this `BIDSFile` (optionally including metadata)\n",
    "* `.get_image()`: Returns the file contents as a nibabel image (only works for image files)\n",
    "* `.get_df()`: Get file contents as a pandas DataFrame (only works for TSV files)\n",
    "* `.get_metadata()`: Returns a dictionary of all metadata found in associated JSON files\n",
    "* `.get_associations()`: Returns a list of all files associated with this one in some way\n",
    "\n",
    "Let's see some of these in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datatype': 'anat', 'extension': '.nii.gz', 'subject': '01', 'suffix': 'T1w'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all the entities associated with this file, and their values\n",
    "bf.get_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AcquisitionMatrixPE': 246,\n",
       " 'AcquisitionNumber': 1,\n",
       " 'AcquisitionTime': '16:43:32.335000',\n",
       " 'BaseResolution': 256,\n",
       " 'CoilCombinationMethod': 'Adaptive Combine',\n",
       " 'CoilString': 'T:HEA;HEP',\n",
       " 'ConversionSoftware': 'dcm2niix',\n",
       " 'ConversionSoftwareVersion': 'v1.0.20230411',\n",
       " 'DeviceSerialNumber': '35119',\n",
       " 'DwellTime': 8.5e-06,\n",
       " 'EchoTime': 0.00298,\n",
       " 'FlipAngle': 9,\n",
       " 'HeudiconvVersion': '1.0.1',\n",
       " 'ImageComments': 'V',\n",
       " 'ImageOrientationPatientDICOM': [0, 1, 0, 0, 0, -1],\n",
       " 'ImageOrientationText': 'Sag',\n",
       " 'ImageType': ['ORIGINAL', 'PRIMARY', 'M', 'ND', 'NORM'],\n",
       " 'ImagingFrequency': 123.251801,\n",
       " 'InPlanePhaseEncodingDirectionDICOM': 'ROW',\n",
       " 'InstitutionAddress': 'Chaucer Road  15,Cambridge,UK,GB,CB2 2EF',\n",
       " 'InstitutionName': 'MRC-CBU',\n",
       " 'InversionTime': 0.9,\n",
       " 'MRAcquisitionType': '3D',\n",
       " 'MagneticFieldStrength': 3,\n",
       " 'Manufacturer': 'Siemens',\n",
       " 'ManufacturersModelName': 'TrioTim',\n",
       " 'MatrixCoilMode': 'GRAPPA',\n",
       " 'Modality': 'MR',\n",
       " 'NonlinearGradientCorrection': True,\n",
       " 'ParallelReductionFactorInPlane': 2}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 30 metadata items associated with this file\n",
    "file_metadata = bf.get_metadata()\n",
    "\n",
    "{k: file_metadata[k] for k in list(file_metadata)[:30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_image()`: Returns the file contents as a `nibabel` image (only works for image files). We can then display the image, for example, using `OrthoSlicer3D`.   \n",
    "\n",
    "**Note:** When using `orthoview()` in notebook, don't forget to close figures afterward again or use %matplotlib inline again, otherwise, you cannot plot any other figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='0e4fac82-64c5-42e2-9e27-cfb396228241'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<OrthoSlicer3D: /imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-01/anat/sub-01_T1w.nii.gz (192, 256, 256)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "bf.get_image().orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.tsv` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where a file has a `.tsv.gz` or `.tsv` extension, it will automatically be created as a `BIDSDataFile`, and we can easily grab the contents as a `DataFrame`.\n",
    "\n",
    "Let's look at the first `events` file from our layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>circle_duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>button_pushed</th>\n",
       "      <th>response_time</th>\n",
       "      <th>stim_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.534</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.158</td>\n",
       "      <td>func/f013.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.273</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.586</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.233</td>\n",
       "      <td>func/f013.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.647</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.546</td>\n",
       "      <td>UNFAMILIAR</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.183</td>\n",
       "      <td>func/u014.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.838</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.597</td>\n",
       "      <td>UNFAMILIAR</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>func/u014.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.978</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.415</td>\n",
       "      <td>UNFAMILIAR</td>\n",
       "      <td>13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.068</td>\n",
       "      <td>func/u016.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    onset  duration  circle_duration  trial_type  trigger  button_pushed  \\\n",
       "0   0.000     0.908            0.534      FAMOUS        5            4.0   \n",
       "1   3.273     0.962            0.586      FAMOUS        6            4.0   \n",
       "2   6.647     0.825            0.546  UNFAMILIAR       13            4.0   \n",
       "3   9.838     0.968            0.597  UNFAMILIAR       14            4.0   \n",
       "4  12.978     0.904            0.415  UNFAMILIAR       13            7.0   \n",
       "\n",
       "   response_time      stim_file  \n",
       "0          2.158  func/f013.bmp  \n",
       "1          1.233  func/f013.bmp  \n",
       "2          1.183  func/u014.bmp  \n",
       "3          0.930  func/u014.bmp  \n",
       "4          1.068  func/u016.bmp  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first events file\n",
    "evfile = layout.get(suffix='events')[0]\n",
    "\n",
    "# Get contents as a DataFrame and show the first few rows\n",
    "df = evfile.get_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `participants` information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-02</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-03</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-04</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sub-05</td>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-06</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sub-07</td>\n",
       "      <td>31</td>\n",
       "      <td>F</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sub-08</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sub-09</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sub-10</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sub-11</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sub-12</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sub-13</td>\n",
       "      <td>25</td>\n",
       "      <td>F</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sub-14</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub-15</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sub-16</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  age sex    group\n",
       "1          sub-01   31   M  control\n",
       "3          sub-02   25   M  control\n",
       "2          sub-03   30   M  control\n",
       "0          sub-04   26   F  control\n",
       "10         sub-05   23   F  control\n",
       "4          sub-06   26   M  control\n",
       "11         sub-07   31   F  control\n",
       "14         sub-08   26   M  control\n",
       "7          sub-09   29   M  control\n",
       "15         sub-10   23   M  control\n",
       "5          sub-11   24   F  control\n",
       "8          sub-12   24   F  control\n",
       "13         sub-13   25   F  control\n",
       "9          sub-14   24   F  control\n",
       "6          sub-15   30   M  control\n",
       "12         sub-16   25   M  control"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants = layout.get(suffix='participants', extension='tsv')[0]\n",
    "\n",
    "df = participants.get_df()\n",
    "df.sort_values(by=['participant_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filename parsing\n",
    "Let's say you have a filename, and you want to manually extract BIDS entities from it. The `parse_file_entities` method provides the facility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': '04',\n",
       " 'task': 'facerecognition',\n",
       " 'run': 01,\n",
       " 'suffix': 'bold',\n",
       " 'extension': '.nii.gz'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.parse_file_entities('some_path_to_bids_file/sub-04_task-facerecognition_run-01_bold.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the same for `BIDSFile` object that we defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': '01', 'suffix': 'T1w', 'datatype': 'anat', 'extension': '.nii.gz'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.parse_file_entities(bf.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix': 'T1w', 'extension': '.nii.gz'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.parse_file_entities(bf.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path construction\n",
    "You may want to create valid BIDS filenames for new files that would sit within your BIDS project. This is useful when you know what entity values you need to write out to, but don’t want to deal with looking up the precise BIDS file-naming syntax. All we need to do is define a dictionary with the name components, and build_path takes care of the rest (including injecting sub-directories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-01/func/sub-01_task-facerecognition_run-02_bold.nii.gz'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = {\n",
    "    'subject': '01',\n",
    "    'run': '02',\n",
    "    'task': 'facerecognition',\n",
    "    'suffix': 'bold'\n",
    "}\n",
    "\n",
    "layout.build_path(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that `_` and `-` have special meaning in BIDS specification. E.g., you can't name your task `face-recognition`, that would not be 'spec-compliant' and would end in an error! However, if you add `validate=False`, you can get away with it (i'e', `layout.build_path(entities, validate=False)`). \n",
    "\n",
    "You can also use `build_path` in more sophisticated ways by defining your own set of matching templates that cover cases not supported by BIDS out of the box. For example, suppose you want to create a template for naming a new `stat` file (containig statistical results of your rMRI analysis). You could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/imaging/correia/da05/workshops/2024-CBU/notebooks/../data/sub-01_task-facerecognition_run-02_type-tval_stat.nii.gz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the pattern to build out of the components passed in the dictionary\n",
    "pattern = \"sub-{subject}_task-{task}_run-{run}_type-{type}_{suffix}.nii.gz\"\n",
    "\n",
    "entities = {\n",
    "    'subject': '01',\n",
    "    'task': 'facerecognition',\n",
    "    'run': '02',\n",
    "    'type': 'tval',\n",
    "    'suffix': 'stat'\n",
    "}\n",
    "\n",
    "# Notice we pass the new pattern as the second argument\n",
    "layout.build_path(entities, pattern, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report generation\n",
    "`PyBIDS` also allows you to automatically create data acquisition reports based on the available `image` and `meta-data` information. This enables a new level of standardisation and transparency. FAIR-ness, meta-analyses, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the BIDSReport function from the reports submodule\n",
    "from bids.reports import BIDSReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only need to apply the `BIDSReport` function to our `layout` and generate our report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-01_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-01_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/layout/models.py:229: UserWarning: Accessing entities as attributes is deprecated as of 0.7. Please use the .entities dictionary instead (i.e., .entities['run'] instead of .run.\n",
      "  warnings.warn(\"Accessing entities as attributes is deprecated as \"\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-02_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-02_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-03_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-03_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-04_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-04_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-05_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-05_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-06_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-06_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-07_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-07_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-08_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-08_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-09_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-09_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-10_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-10_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-11_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-11_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-12_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-12_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-13_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-13_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-14_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-14_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-15_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-15_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns detected: 6\n",
      "Remember to double-check everything and to replace <deg> with a degree symbol.\n",
      "In session None, MR data were acquired using a 3-Tesla Siemens TrioTim MRI scanner.\n",
      "\tOne run of T1-weighted SP\\MP\\OSP GR\\IR (GR\\IR) single-echo structural MRI data were collected (256 slices; repetition time, TR=2250ms; echo time, TE=2.98ms; flip angle, FA=9<deg>; field of view, FOV=192x256mm; matrix size=192x256; voxel size=1x1x1mm).\n",
      "\tA spoiled gradient recalled (GR) field map (phase encoding: anterior to posterior; 33 slices in interleaved ascending order; repetition time, TR=400ms; echo time 1 / 2, TE1/2=5.197.65ms; flip angle, FA=60<deg>; field of view, FOV=192x192mm; matrix size=64x64; voxel size=3x3x3.75mm) was acquired for the first, second, third, fourth, fifth, sixth, seventh, eighth, and ninth runs of the facerecognition BOLD scan.\n",
      "\tNine runs of facerecognition segmented k-space echo planar (EP) single-echo fMRI data were collected (33 slices in interleaved ascending order; repetition time, TR=2000ms; echo time, TE=30ms; flip angle, FA=78<deg>; field of view, FOV=192x192mm; matrix size=64x64; voxel size=3x3x3.75mm). Run duration was 6:56 minutes, during which 208 volumes were acquired.\n",
      "\n",
      "Dicoms were converted to NIfTI-1 format using dcm2niix (v1.0.20230411). This section was (in part) generated automatically using pybids (0.16.1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-16_acq-func_magnitude1.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n",
      "/home/da05/.conda/envs/fMRI/lib/python3.10/site-packages/bids/reports/parsing.py:386: UserWarning: sub-16_acq-func_magnitude2.nii.gz not yet supported.\n",
      "  warnings.warn(group[0].filename + \" not yet supported.\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize a report for the dataset\n",
    "report = BIDSReport(layout)\n",
    "\n",
    "# Method generate returns a Counter of unique descriptions across subjects\n",
    "try:\n",
    "    descriptions = report.generate()\n",
    "    pub_description = descriptions.most_common()[0][0]\n",
    "    print(pub_description)\n",
    "except IndexError:\n",
    "    print('Sorry, it seems that the dataset is not complete and report cannot be generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you spot an error in the report?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
