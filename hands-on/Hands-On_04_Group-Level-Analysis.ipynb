{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group level statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First you will need to download the example dataset by executing the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloding the example dataset ... please wait ... \")\n",
    "![ ! -d \"FaceRecognition\" ] && wget \"FaceRecognition.zip\" \"https://dl.dropboxusercontent.com/s/q030cu844joczm6/FaceRecognition.zip\"\n",
    "![ ! -d \"FaceRecognition\" ] && unzip -q ~/hands-on/FaceRecognition.zip -d ~/hands-on && rm ~/hands-on/FaceRecognition.zip \n",
    "print(\"Dataset downloaded, carry on!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving First-Level results\n",
    "As we now have the same contrast results from multiple `subjects`, we can define our `group level model`. First, we need to gather the `individual contrast maps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bids.layout import BIDSLayout\n",
    "\n",
    "ds_path = 'FaceRecognition'\n",
    "# Initialize the BIDS layout and include the derivatives in it\n",
    "layout = BIDSLayout(os.path.join(ds_path, 'data/bids'), derivatives = True)\n",
    "# Attach the results folder to the layout. It must complay with BIDS standards. \n",
    "# And must include dataset_description.json file!\n",
    "layout.add_derivatives(os.path.join(ds_path, \"results\", \"first-level-2mm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect individual t-maps (`stat`) that represent the BOLD activity estimate divided by the uncertainty about this estimate. \n",
    "\n",
    "Let's first look at only the **Faces > Scrambled** contrast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = 'FacesScrambled'\n",
    "stat_files = layout.get(desc = contrast, suffix='stat', extension = '.nii.gz')\n",
    "print(*stat_files, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to display subject ID on top of their individual t-maps. Therefore we need to link each stat file with the corresponding subject ID. There are several ways to do this. The simplest seems to retrieve the subject list from the BIDS layout. But `PyBIDS` returns unsorted subject list, that's a bit problematic. And for some reason, sort() does not work on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layout.get_subjects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore I will sort it this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = sorted(list(set([f.get_entities().get(\"subject\") for f in stat_files])))\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying subject t-maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "for i, stat_map in enumerate(stat_files):\n",
    "    plotting.plot_glass_brain(stat_map.path, \n",
    "                              title = 'sub-' + subjects[i],\n",
    "                              axes = axes[i],\n",
    "                              plot_abs = False, \n",
    "                              display_mode='x')\n",
    "fig.suptitle(contrast + ', unthresholded t-maps')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate second level model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step includes the definition of a `design matrix`. Here we will want to run a simple `one-sample t-test`. We just need to indicate as many `1` as we have subjects with first-level results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "design_matrix = pd.DataFrame(\n",
    "    [1] * len(stat_files),\n",
    "    columns=['intercept'])\n",
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model specification and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm = 8.0)\n",
    "second_level_model = second_level_model.fit(\n",
    "    stat_files,\n",
    "    design_matrix = design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = second_level_model.compute_contrast(output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding and plotting\n",
    "\n",
    "In the example dataset, there are only 2 subjects. So, the results will be rather poor. Strict thresholding wouldn't get any significant voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.thresholding import threshold_stats_img\n",
    "\n",
    "cluster_map, threshold = threshold_stats_img(\n",
    "    z_map, alpha=0.05, \n",
    "    height_control='fpr', \n",
    "    cluster_threshold=20,\n",
    "    two_sided=False)\n",
    "\n",
    "# displaying on mni152 template brain\n",
    "from nilearn.datasets import load_mni152_template\n",
    "template = load_mni152_template()\n",
    "\n",
    "print('Uncorrected p<.05 threshold: %.3f' % threshold)\n",
    "plotting.plot_stat_map(\n",
    "    cluster_map, \n",
    "    threshold = threshold,       \n",
    "    display_mode = 'ortho',\n",
    "    cut_coords = [37,-62,-14],\n",
    "    black_bg = True,\n",
    "    bg_img = template,\n",
    "    title = contrast + ' ()')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map, threshold = threshold_stats_img(\n",
    "    z_map, alpha=.05, \n",
    "    height_control='bonferroni', \n",
    "    cluster_threshold=0,\n",
    "    two_sided=False)\n",
    "\n",
    "print('FWE p<.05 threshold: %.3f' % threshold)\n",
    "plotting.plot_stat_map(\n",
    "    cluster_map, \n",
    "    threshold = threshold,       \n",
    "    display_mode = 'ortho',\n",
    "    cut_coords = [37,-62,-14],\n",
    "    black_bg = True,\n",
    "    bg_img = template,\n",
    "    title = contrast + ' (FWE p<.05)')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at a 3D brain using `plotly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "\n",
    "cluster_map, threshold = threshold_stats_img(\n",
    "    z_map, alpha = 0.05, \n",
    "    height_control = 'fpr',\n",
    "    cluster_threshold = 20,\n",
    "    two_sided = True)\n",
    "\n",
    "view = plotting.view_img_on_surf(cluster_map, threshold=threshold)\n",
    "# view.open_in_browser()\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more summary results. Here we will get a cluster table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import get_clusters_table\n",
    "get_clusters_table(z_map, threshold, cluster_threshold=20, two_sided=False, min_distance=8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can create more complete reports with [nilearn.reporting](https://nilearn.github.io/dev/modules/generated/nilearn.reporting.make_glm_report.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from nilearn.reporting import make_glm_report\n",
    "\n",
    "report = make_glm_report(model = second_level_model,\n",
    "                         contrasts = 'intercept',\n",
    "                         threshold = 3,\n",
    "                         cluster_threshold = 30,\n",
    "                         display_mode = 'ortho'\n",
    "                         )\n",
    "\n",
    "report\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use ['atlasreader'](https://github.com/miykael/atlasreader) package, as demonstrated in the below script to create reports for all our contrasts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second level for multiple contrasts\n",
    "\n",
    "The script below will generate outputs of group-level results for multiple contrasts. \n",
    "\n",
    "In this example, we want to threshold the results to **p < .01, uncorrected, with cluster threshold 10**. **(We only have 2 subjects in this example dataset, a more strict threshold might not return any significant results. But you can give it a try!)**\n",
    "\n",
    "In addition to getting our result maps, we will use *atlasreader* to generate result tables and peak cluster images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# ======================================================================\n",
    "# Dace ApÅ¡valka (MRC CBU 2022)\n",
    "# Group level fMRI analysis using Nilearn\n",
    "# ======================================================================\n",
    "\n",
    "# ======================================================================\n",
    "# IMPORT RELEVANT PACKAGES\n",
    "# ======================================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bids.layout import BIDSLayout\n",
    "from nilearn.datasets import load_mni152_template\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm.thresholding import threshold_stats_img\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from atlasreader import create_output\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# WHICH CONTRASTS\n",
    "# ======================================================================\n",
    "contrasts = {'FamousUnfamiliar': 'Famous > Unfamiliar',\n",
    "             'UnfamiliarFamous': 'Unfamiliar > Famous',\n",
    "             'FacesScrambled': 'Faces > Scrambled',\n",
    "             'ScrambledFaces': 'Scrambled > Faces'}\n",
    "# ======================================================================\n",
    "# WHAT THRESHOLD\n",
    "# ======================================================================\n",
    "height_control ='fpr' # bonferroni is FWE; fpr is uncorrected; \n",
    "alpha = .01\n",
    "cluster_threshold = 10\n",
    "\n",
    "# ======================================================================\n",
    "# DEFINE PATHS\n",
    "# ======================================================================\n",
    "ds_path = 'FaceRecognition'\n",
    "\n",
    "outdir = os.path.join(ds_path, 'results', 'group-level_' + height_control + str(alpha)[2:] + 'k' + \\\n",
    "                      str(cluster_threshold))\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "                      \n",
    "# ======================================================================\n",
    "# PREPARE OTHER SUFF\n",
    "# ======================================================================\n",
    "\n",
    "# Initialize the BIDS layout and include the derivatives in it\n",
    "layout = BIDSLayout(os.path.join(ds_path, 'data/bids'), derivatives=True)\n",
    "layout.add_derivatives(os.path.join(ds_path, \"results\", \"first-level-2mm\"))\n",
    "\n",
    "# load a template to resample images to if needed\n",
    "template = load_mni152_template()\n",
    "\n",
    "# ======================================================================\n",
    "# PERFORM GROUP LEVEL ANALYSIS PER CONTRAST\n",
    "# ======================================================================\n",
    "\n",
    "for contrast_id, contrast_val in contrasts.items():\n",
    "    # get the first level result maps\n",
    "    stat_files = layout.get(desc = contrast_id, suffix = 'stat', extension = '.nii.gz')\n",
    "    \n",
    "    # generate the result file name\n",
    "    result_name = 'group_zmap_' + contrast_id + '_' + height_control + str(alpha)[2:] + 'k' + str(cluster_threshold)\n",
    "    \n",
    "    # create the group level design matrix. Here just a one-sample t-test\n",
    "    design_matrix = pd.DataFrame([1] * len(stat_files),\n",
    "                                 columns=['intercept'])\n",
    "    \n",
    "    # define and compute the glm\n",
    "    second_level_model = SecondLevelModel(smoothing_fwhm = 8.0)\n",
    "    second_level_model = second_level_model.fit(\n",
    "        stat_files,\n",
    "        design_matrix = design_matrix)\n",
    "    \n",
    "    # get the z-map for the contrast of interest\n",
    "    z_map = second_level_model.compute_contrast(output_type='z_score')\n",
    "        \n",
    "    # threshold the z-map\n",
    "    thresholded_map, threshold = threshold_stats_img(\n",
    "        z_map, \n",
    "        alpha = alpha,\n",
    "        height_control = height_control,\n",
    "        two_sided = False,\n",
    "        cluster_threshold = cluster_threshold)\n",
    "    \n",
    "    # get peaks   \n",
    "    peaks = get_clusters_table(thresholded_map, stat_threshold=threshold)\n",
    "    \n",
    "    # if there is any peak then save the map and generate report\n",
    "    if len(peaks) != 0:\n",
    "        print('Creating output for', contrast_val)\n",
    "        fname = os.path.join(outdir, result_name + '.nii.gz')\n",
    "        thresholded_map.to_filename(fname)\n",
    "\n",
    "        # generate and save also atlasreader output\n",
    "        create_output(\n",
    "            fname, \n",
    "            cluster_extent = cluster_threshold, \n",
    "            voxel_thresh = threshold,\n",
    "            direction = 'pos',\n",
    "            outdir = os.path.join(outdir, 'atlasreader', contrast_id)\n",
    "        )\n",
    "    else:\n",
    "        print('No significant voxels for', contrast_val)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary results\n",
    "\n",
    "Let's now loop through the generated output and display the peak image and results table for each contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image\n",
    "\n",
    "contrasts = {'FamousUnfamiliar': 'Famous > Unfamiliar',\n",
    "             'UnfamiliarFamous': 'Unfamiliar > Famous',\n",
    "             'FacesScrambled': 'Faces > Scrambled',\n",
    "             'ScrambledFaces': 'Scrambled > Faces'}\n",
    "\n",
    "for contrast_id, contrast_val in contrasts.items():\n",
    "    # results folder\n",
    "    results_dir = os.path.join(ds_path, 'results', 'group-level_fpr01k10', 'atlasreader', contrast_id)\n",
    "    \n",
    "    # if the directory exists\n",
    "    if os.path.exists(results_dir):\n",
    "        print('Results for', contrast_val)\n",
    "        \n",
    "        # find the image file        \n",
    "        cluster1 = glob.glob(os.path.join(results_dir, '*cluster01.png'))        \n",
    "        # find peak table\n",
    "        peaks = glob.glob(os.path.join(results_dir, '*_peaks.csv'))\n",
    "        \n",
    "        # display the image\n",
    "        display(Image(cluster1[0]))\n",
    "        # display the table\n",
    "        display(pd.read_csv(peaks[0]))\n",
    "    else:\n",
    "        print(contrast_val, 'does not have significant results')            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "182px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "874.85px",
    "left": "2183px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
