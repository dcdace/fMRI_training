{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First you will need to download the example dataset by executing the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloding the example dataset ... please wait ... \")\n",
    "![ ! -d \"FaceRecognition\" ] && wget \"FaceRecognition.zip\" \"https://dl.dropboxusercontent.com/s/q030cu844joczm6/FaceRecognition.zip\"\n",
    "![ ! -d \"FaceRecognition\" ] && unzip -q ~/hands-on/FaceRecognition.zip -d ~/hands-on && rm ~/hands-on/FaceRecognition.zip \n",
    "print(\"Dataset downloaded, carry on!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Level Analysis with Nilearn\n",
    "\n",
    "[Nilearn](https://nilearn.github.io/stable/index.html) `GLM stats` module allows fast and easy MRI statistical analysis. It leverages `Nibabel` and other `Python` libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the preprocessed (fMRIprep) data\n",
    "\n",
    "BIDS applications, such as `fMRIprep`, output data into a data structure similar to `BIDS` organization principals. And these data can also be inspected using [PyBIDS](https://bids-standard.github.io/pybids/index.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bids.layout import BIDSLayout\n",
    "\n",
    "ds_path = 'FaceRecognition/data/bids'\n",
    "\n",
    "# Initialize the BIDS layout and include the derivatives in it\n",
    "layout = BIDSLayout(ds_path, derivatives = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `PyBIDS` we can easlily find the proprocessed files that we'd need for the analysis. Let's get the `sub-04` **preprocessed** anatomical and functional `MNI152NLin2009cAsym` space image files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sID = '04'\n",
    "anat = layout.get(subject=sID, datatype='anat', space='MNI152NLin2009cAsym', desc='preproc', extension='.nii.gz', \\\n",
    "                  return_type='filename')\n",
    "print('Subject''s', sID, 'preprocessed anatomical image:')\n",
    "print(*anat, sep='\\n')\n",
    "\n",
    "bold = layout.get(subject=sID, datatype='func', space='MNI152NLin2009cAsym', desc='preproc', extension='.nii.gz', \\\n",
    "                 return_type='filename')\n",
    "print('\\nSubject''s', sID, 'preprocessed functional images:')\n",
    "print(*bold, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model components\n",
    "\n",
    "A GLM model has an **outcome variable** (the BOLD signal/our MRI images) and **predictors** (Events, Confounds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRI images\n",
    "We need to specify which images we want to analyse. \n",
    "\n",
    "Here we will analyse `sub-04` 9 functional runs. We will also specify the subject's anatomical image (warped to the standard space) to use it as a background image when plotting results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events\n",
    "\n",
    "We also need to specify the events that were happaning during the functional acquisitions. The events files are stored in the `func` foder and we can find them with `PyBIDS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = layout.get(subject=sID, datatype='func', suffix='events', extension=\".tsv\", return_type='filename')\n",
    "print('Subject''s', sID, 'event files:')\n",
    "print(*events, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the first rows of events of the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas is a library for data manipulation \n",
    "events_run1 = pd.read_table(events[0])\n",
    "events_run1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we also want to include confounds computed during preprocessing (e.g., motion artifacts) as regressors of no interest. The confounds are computed by `fmriprep` and can be found in `derivatives/fmriprep/{sub}/func/` directory.\n",
    "\n",
    "Let's find these files with `PyBIDS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds = layout.get(subject=sID, datatype='func', desc='confounds', extension=\".tsv\", return_type='filename')\n",
    "print('Subject''s', sID, 'confound files:')\n",
    "print(*confounds, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of all confound names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confounds_run1 = pd.read_table(confounds[0])\n",
    "list(confounds_run1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of confounds created:\n",
    "len(list(confounds_run1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fMRIPrep pipeline generates a large array of possible confounds. The most well established confounding variables in neuroimaging are the six head-motion parameters (three rotations and three translations) - the common output of the head-motion correction (also known as realignment) of popular fMRI preprocessing software such as SPM or FSL. Let's include them in our model. \n",
    "\n",
    "Let's display these confounds of the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds_of_interest = ['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']\n",
    "confounds_run1[confounds_of_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get the confounds of interest of all runs. These will be included in our `GLM` design. We will create a list of confound tables (9 tables). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds_glm = []\n",
    "for conf_file in confounds:\n",
    "    this_conf = pd.read_table(conf_file)\n",
    "    conf_subset = this_conf[confounds_of_interest].fillna(0) # replace NaN with 0\n",
    "    confounds_glm.append(conf_subset)\n",
    "    \n",
    "print(type(confounds_glm))\n",
    "print(len(confounds_glm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the GLM analysis\n",
    "\n",
    "It is now time to create and estimate a ``FirstLevelModel`` object, that will generate the *design matrix*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the First Level Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of important parameters one needs to define within a `FirstLevelModel` and the majority of them will have a prominent influence on your results. [Check the documentation!](https://nilearn.github.io/stable/modules/generated/nilearn.glm.first_level.FirstLevelModel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model specification, we need the TR of the functional images, luckily we can extract this information with `PyBIDS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the TR\n",
    "TR = layout.get_tr()\n",
    "print('TR:', TR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can specify the model with the parameters of our choice. Here we will specify the folowing:\n",
    "* **t_r**, of course\n",
    "* **slice_time_ref**: *This parameter indicates the time of the reference slice used in the slice timing preprocessing step of the experimental runs. It is expressed as a percentage of the t_r (time repetition), so it can have values between 0. and 1. Default=0.* Let's see if we get this information from our fMRIPrep Methods. \n",
    "* **hrf_model**: defines the HRF model to be used.\n",
    "    * \n",
    "\n",
    "        ‘spm’: This is the HRF model used in SPM. See nilearn.glm.first_level.spm_hrf.\n",
    "\n",
    "        ‘spm + derivative’: SPM model plus its time derivative. This gives 2 regressors. See nilearn.glm.first_level.spm_hrf, and nilearn.glm.first_level.spm_time_derivative.\n",
    "\n",
    "        ‘spm + derivative + dispersion’: Idem, plus dispersion derivative. This gives 3 regressors. See nilearn.glm.first_level.spm_hrf, nilearn.glm.first_level.spm_time_derivative, and nilearn.glm.first_level.spm_dispersion_derivative.\n",
    "\n",
    "        ‘glover’: This corresponds to the Glover HRF. See nilearn.glm.first_level.glover_hrf.\n",
    "\n",
    "        ‘glover + derivative’: The Glover HRF + time derivative. This gives 2 regressors. See nilearn.glm.first_level.glover_hrf, and nilearn.glm.first_level.glover_time_derivative.\n",
    "\n",
    "        ‘glover + derivative + dispersion’: Idem, plus dispersion derivative. This gives 3 regressors. See nilearn.glm.first_level.glover_hrf, nilearn.glm.first_level.glover_time_derivative, and nilearn.glm.first_level.glover_dispersion_derivative.\n",
    "\n",
    "        ‘fir’: Finite impulse response basis. This is a set of delayed dirac models.\n",
    "\n",
    "* **drift_model**: specifies the desired drift model for the design matrices. It can be ‘polynomial’, ‘cosine’ or None. Default=’cosine’.\n",
    "* **high_pass**: specifies the cut frequency of the high-pass filter in Hz for the design matrices. Used only if drift_model is ‘cosine’. Default=0.01 (1/128, as in SPM).\n",
    "* **smoothing_fwhm**: the full-width at half maximum in millimeters of the spatial smoothing to apply to the signal (smoothing was not done in fMRIPrep!).\n",
    "* **noise_model**: {‘ar1’, ‘ols’} The temporal variance model. Default=’ar1’.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "fmri_glm = FirstLevelModel(\n",
    "    t_r = TR,\n",
    "    slice_time_ref = TR/2,\n",
    "    hrf_model = 'spm',\n",
    "    drift_model = 'Cosine',\n",
    "    high_pass = 1./128,\n",
    "    smoothing_fwhm = 6,\n",
    "    noise_model = 'ar1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model\n",
    "\n",
    "Now that we have specified the model, we can run it on our specified data. We need to include the list of our functional image files (we named that `bold`), the list of events timing files (we named that `events`), and the list of our confound tables (one per run; which we named `confounds_glm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fmri_glm = fmri_glm.fit(bold, events, confounds_glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Design Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the design matrix of our `GLM` model (rows represent time, and columns contain the predictors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrices = fmri_glm.design_matrices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `design_matrices` is a list of 9 tables (one per run). Let's look at the first run's design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the design matrix, we can extract and plot the expected signal of our conditions. Here we will plot it for the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = design_matrices[0][['FAMOUS', 'UNFAMILIAR']]\n",
    "dm.columns.name = 'Condition'\n",
    "dm.index.name = 'Seconds'\n",
    "dm.plot(figsize=(12,4), title='Expected responses per condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How was this expected signal obtained?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how the modelled noise regressors look\n",
    "dm = design_matrices[0][['drift_1','drift_2', 'drift_3', 'drift_4']]\n",
    "dm.columns.name = 'Regressor'\n",
    "dm.index.name = 'Seconds'\n",
    "dm.plot(figsize=(12,4), title='Expected signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the actual design matrix (here again for the first run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_design_matrix\n",
    "plot_design_matrix(design_matrices[0], output_file=None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting voxels with significant effects\n",
    "Now we will compute fixed effects of the 9 runs and generate related images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrast specification\n",
    "If we have the same number of regressors in each run, we can specify the contrast only for one run and it would automatically be reused for other runs.\n",
    "\n",
    "However, in this dataset we can't do that. One of the subjects have one regressor less (the drift parameter) in one of the runs (because this run was shorter than the other runs; 170 vs 208 volumes).\n",
    "\n",
    "Therefore, I here create contrasts for each run separately and add them to a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_list = []\n",
    "import numpy as np\n",
    "for design_matrix in design_matrices:\n",
    "    \n",
    "    \"\"\"A small routine to append zeros in contrast vectors\"\"\"\n",
    "    n_columns = design_matrix.shape[1] #number of predictors in our model\n",
    "    def pad_vector(contrast_, n_columns):    \n",
    "        return np.hstack((contrast_, np.zeros(n_columns - len(contrast_))))\n",
    "    \n",
    "    contrasts = {'Famous_Unfamiliar': pad_vector([1, 0, 0, -1], n_columns),\n",
    "                'Unfamiliar_Famous': pad_vector([-1, 0, 0, 1], n_columns),\n",
    "                'Faces_Scrambled': pad_vector([1, 0, -2, 1], n_columns),\n",
    "                'Scrambled_Faces': pad_vector([-1, 0, 2, -1], n_columns),\n",
    "                 'EffectsOfInterest': np.eye(n_columns)[[0,2,3]]}\n",
    "    \n",
    "    contrast_list.append(contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the contrasts for the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_contrast_matrix\n",
    "for key, values in contrast_list[0].items():\n",
    "    plot_contrast_matrix(values, design_matrix=design_matrices[0])\n",
    "    plt.suptitle(key)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing result maps\n",
    "\n",
    "You can compute the `effect size` maps, `t-statistics` maps, `z-scores` and some other types. See the [documentation](https://nilearn.github.io/dev/modules/generated/nilearn.glm.Contrast.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compute the estimated effect. It is in BOLD signal unit, but has no statistical guarantees, because it does not take into account the associated variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_map = fmri_glm.compute_contrast([c['Faces_Scrambled'] for c in contrast_list],\n",
    "                                    output_type='effect_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get statistical significance, we form a `t-statistic`, and directly convert is into `z-scale`. The `z-scale` means that the values are scaled to match a standard Gaussian distribution (mean=`0`, variance=`1`), across voxels, if there were now effects in the data. (To get a `t-map` instead, you'd need to specify `output_type='stat'`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = fmri_glm.compute_contrast([c['Faces_Scrambled'] for c in contrast_list],\n",
    "                                  output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting thresholded maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An arbitrary z threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the thresholded z-score map on top of the subject's anatomical image. Let's use arbitrarily a threshold of `3.0` in `z-scale`. We'll see later how to use corrected thresholds. \n",
    "\n",
    "See the `plot_stat_map` [documentation](https://nilearn.github.io/dev/modules/generated/nilearn.plotting.plot_stat_map.html) for all the possible parameters you can specify to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map, plot_glass_brain\n",
    "\n",
    "plot_stat_map(\n",
    "    z_map, \n",
    "    bg_img = anat[0], \n",
    "    threshold=  3.0,\n",
    "    display_mode = 'ortho', black_bg=True,\n",
    "    title =' Faces > Scrambled (Z>3)'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot our maps as glass (trasnparent) brain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_glass_brain(z_map, threshold = 3.0, black_bg = True, plot_abs = False,\n",
    "                 title='Faces > Scrambled (Z>3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical signifiance testing\n",
    "One should worry about the statistical validity of the procedure: here we used an arbitrary threshold of 3.0 but the threshold should provide some guarantees on the risk of false detections (aka `type-1` errors in statistics). One\n",
    "first suggestion is to **control the false positive rate** (`fpr`) at a certain level, e.g. `p < .001`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control the false positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the statistical threshold\n",
    "from nilearn.glm.thresholding import threshold_stats_img\n",
    "\n",
    "_, threshold = threshold_stats_img(z_map, alpha = .001, height_control = 'fpr')\n",
    "\n",
    "print('Uncorrected p<.001 threshold: %.3f' % threshold)\n",
    "\n",
    "# plot the thresholded map\n",
    "plot_stat_map(z_map, bg_img = anat[0], threshold = threshold,\n",
    "              display_mode = 'ortho', black_bg = True,\n",
    "              title = 'Faces > Scrambled  (p<.001, Uncorrected)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Wise Error (FWE) correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above is not corrected for **multiple comparisons**. After all, we are performing thousands of `t-tests` here (one for each voxel). A more conservative solution is to control the **family wise error** rate, i.e. the probability of making ony one false detection, say at `5%`. For that we use the so-called `Bonferroni correction`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, threshold = threshold_stats_img(z_map, alpha = .05, height_control = 'bonferroni')\n",
    "\n",
    "print('Bonferroni-corrected, p<.05 threshold: %.3f' % threshold)\n",
    "\n",
    "plot_stat_map(z_map, bg_img = anat[0], threshold = threshold,\n",
    "              display_mode = 'ortho', black_bg = True,\n",
    "              title = 'Faces > Scrambled  (p<.05, FWE corrected)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite conservative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Discovery Rate (FDR) correction\n",
    "\n",
    "A popular alternative is to control the **false discovery rate**, i.e. the expected proportion of false discoveries among detections. This is called the false disovery rate. `height_control='fdr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, threshold = threshold_stats_img(z_map, alpha = .05, height_control = 'fdr')\n",
    "\n",
    "print('FDR, p<.05 threshold: %.3f' % threshold)\n",
    "\n",
    "plot_stat_map(z_map, bg_img = anat[0], threshold = threshold,\n",
    "              display_mode = 'ortho', black_bg = True,\n",
    "              title = 'Faces > Scrambled  (p<.05, FDR corrected)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a common practice to discard isolated voxels from the images. It is possible to generate a thresholded map with small clusters removed by providing a `cluster_threshold` argument. Here clusters smaller than `20` voxels will be discarded from the `FDR` corrected map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_map, threshold = threshold_stats_img(\n",
    "    z_map, alpha = .05, height_control='fdr', cluster_threshold = 20)\n",
    "\n",
    "plot_stat_map(cluster_map, bg_img=anat[0], threshold=threshold,\n",
    "              display_mode='ortho', black_bg=True, colorbar=False,\n",
    "              title='Faces > Scrambled (p<.05, FDR corrected, k=20')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps for all contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Computing contrasts')\n",
    "import warnings\n",
    "from nilearn import plotting\n",
    "from nilearn.reporting import get_clusters_table\n",
    "\n",
    "# Avoid getting warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    # Iterate on contrasts\n",
    "    for contrast_id in contrast_list[0].keys():\n",
    "        print(\"Contrast: %s\" % contrast_id)\n",
    "        # compute the contrasts\n",
    "        z_map = fmri_glm.compute_contrast(\n",
    "            [c[contrast_id] for c in contrast_list], output_type='z_score')\n",
    "        # get threshold\n",
    "        cluster_map, threshold = threshold_stats_img(z_map, alpha=.05, height_control='bonferroni', cluster_threshold=10)\n",
    "        # get peak clusters    \n",
    "        peaks = get_clusters_table(z_map, stat_threshold=threshold,\n",
    "                               cluster_threshold=20)\n",
    "        if len(peaks) != 0: \n",
    "            peak_xyz = peaks.loc[0, ['X', 'Y','Z']]\n",
    "            # plot\n",
    "            plotting.plot_stat_map(\n",
    "                cluster_map, \n",
    "                bg_img = anat[0], \n",
    "                threshold = threshold, \n",
    "                display_mode='ortho',\n",
    "                cut_coords = peak_xyz, \n",
    "                black_bg = True, \n",
    "                title = contrast_id + ' FWE p<.05, k=20')\n",
    "            plotting.show()\n",
    "        else:\n",
    "            print('\\t', contrast_id, 'has no significant voxels.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visually compare different models\n",
    "\n",
    "Let's compare our original model with some other possible models to see how different parameters affect our results. \n",
    "\n",
    "**Note:** This is not to fish for results that most match our hypothesis!\n",
    "\n",
    "Some examples we could explore,\n",
    "* a model without slice_time_ref adjusted\n",
    "* a model wiht different confounds\n",
    "* a model with different noise models\n",
    "* a model with a different hrf model (contrasts might need adjusting!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***If you are doing this in the interactive online notebook and kernel keeps dying, you could include only part of the subject's runs in the analysis. In the example below, I only include first 3 runs.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(\n",
    "    t_r = TR,\n",
    "    slice_time_ref = 0,\n",
    "    hrf_model = 'spm',\n",
    "    drift_model = 'Cosine',\n",
    "    high_pass = 1./128,\n",
    "    smoothing_fwhm = 4,\n",
    "    noise_model = 'ar1', \n",
    "    minimize_memory = False\n",
    ")\n",
    "fmri_glm = fmri_glm.fit(bold[:3], events[:3], confounds_glm[:3])\n",
    "# ignore warnings about unused events columns\n",
    "warnings.resetwarnings()\n",
    "warnings.simplefilter('ignore')\n",
    "##\n",
    "design_matrices = fmri_glm.design_matrices_\n",
    "plot_design_matrix(design_matrices[0], output_file=None)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_list = []\n",
    "for design_matrix in design_matrices:\n",
    "    \"\"\"A small routine to append zeros in contrast vectors\"\"\"\n",
    "    n_columns = design_matrix.shape[1] #number of predictors in our model\n",
    "    def pad_vector(contrast_, n_columns):    \n",
    "        return np.hstack((contrast_, np.zeros(n_columns - len(contrast_))))\n",
    "    \n",
    "    contrasts = {'Faces_Scrambled': pad_vector([1, 0, -2, 1], n_columns)}\n",
    "    contrast_list.append(contrasts)\n",
    "\n",
    "z_map = fmri_glm.compute_contrast([c['Faces_Scrambled'] for c in contrast_list],\n",
    "                                      output_type='z_score')\n",
    "    \n",
    "_, threshold = threshold_stats_img(z_map, alpha=.001, height_control='fpr')\n",
    "    \n",
    "plot_stat_map(z_map, bg_img=anat[0], threshold=threshold,\n",
    "                  display_mode='ortho', black_bg=True,\n",
    "                  title='Faces > Scrambled (unc. > .001)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some other models yourself! Refer to the [in-class notebook](https://nbviewer.org/github/dcdace/COGNESTIC-fMRI/blob/master/class-materials/04_nb_Subject-Level-Analysis.ipynb?flush_cache=true#The-impact-of-first-level-model-parameters) for help if needed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "874.85px",
    "left": "2183px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
